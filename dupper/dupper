#!/usr/bin/perl
#
# $Id$
# By Jeremy Mates <mailto:jmates@sial.org>
#
# Removes duplicate files.  Perl only implementation.
#
# Distributed under the Artistic License:
# http://www.sial.org/artistic_license.txt
#
######################################################################
#
# MODULES

use Carp;
use Digest::MD5;
use File::Spec;
use Getopt::Std;

use strict;
use vars qw:$VERSION:;

######################################################################
#
# CONSTANTS

($VERSION = '$Revision$ ') =~ s/[^0-9.]//g;

my (%opts, $verbose, %check);

my $dig = new Digest::MD5; # we reset this for each file

######################################################################
#
# MAIN

# parse command-line options
getopts('h?vp:s:', \%opts);

help() if exists($opts{'h'}) || exists($opts{'?'});

$verbose = 1 if exists $opts{'v'};

# read from STDIN if no args left
chomp(@ARGV = <STDIN>) unless @ARGV;

# and flag the help text if nothing from STDIN
help() unless @ARGV;

# loop over arguments which presumably are a bunch of directories
foreach ( @ARGV ) {
    parsedir($_, 0, $_) if -d;
}

######################################################################
#
# SUBROUTINES

sub parsedir {
    my $dir = shift;
    my $level = shift;
    my $previous = shift;

    unless (opendir (DIR, $dir)) {
	warn 'Problem reading ', $dir, ': ', $!, "\n";
	return;
    }

    # loop over sorted contents of directory, skipping . and .. specials
    foreach (sort (readdir (DIR))) {
	next if /^\.{1,2}$/;
	my $pti = File::Spec->catfile($dir, $_);

	next if -l $pti; # skip links. Links bad. :)
	
	# only deal with files when doing sums
	if (-f $pti) {
	    # first check whether we skip this file
	    if (exists $opts{'s'}) {
		my $result = eval "return 1 if( " . $opts{'s'} . " );";
		
		if($@) {
		    chomp($@);
		    die "Skip error: ", $@; # croak on errors
		}
		
		if($result) {
		    next;
		}
	    }

	    # open up file, then hand it off to MD5 module
	    unless (open (FILE, $pti)) {
		warn 'Problem reading ', $pti, ': ', $!, "\n";
		next;
	    }

            # reset checksum object, then get new Checksum on file
	    $dig->new();
	    $dig->addfile(*FILE);
	    my $sum = $dig->hexdigest;

	    close (FILE);
	    
	    # either add new checksum to hash, or delete the duplicate file
	    unless (exists $check{$sum}) {
		$check{$sum} = $pti;
	    } else {
		# need an interactive mode, or at least a report mode!!
		warn "unlink ", $pti, "\n" if $verbose;
		unless (unlink $pti) {
		    warn 'Problem unlinking ', $pti, ' (dup ', $check{$sum}, '): ', $!, "\n";
		}
	    }
	} elsif (-d $pti) {
            # see whether this dir needs to be pruned from the search
            if (exists $opts{'p'}) {
                my $results = eval "return 1 if( " . $opts{'p'} . " );";
                
                if($@) {
                    chomp($@);
                    die "Prune error: ", $@; # croak on errors
                }

                if($results) {
		    warn "Pruned $pti\n" if $verbose;
                    next;
                }
            }

	    # recurse
	    parsedir ($pti, $level + 1, $dir);
	}
    }
}

# a generic help blarb
sub help {
    print <<"HELP";
$0 v.$VERSION
Usage: $0 [options]

Removes duplicate files based on checksum comparison.

Options:
  -h/-?  Display this message
  -v     Verbose mode, a little bit more chatty.

  -s xx  Perl expression that will result in the current file (stored in \$_)
         being skipped if the expression turns out to be "true."  Example:

         -s 'm/^\\.rsrc\$/'

         Would skip the checksum on '.rsrc' files.

  -p xx  Perl expression that will result in the current directory (stored in 
         \$_) being pruned out of the tree.  Like config dirs, for example:

         -p 'm/etc/'

         Both -s and -p expressions should use the shortcut _ operator in
         any stat() calls to avoid race conditions.

HELP
    exit;
}
